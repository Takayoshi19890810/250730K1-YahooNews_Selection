name: Daily News Scraper to Google Drive

on:
  workflow_dispatch:  # 手動実行
  schedule:
    - cron: '15 6 * * *'  # JST 15:15（UTC 6:15）

jobs:
  scrape-and-upload:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install Chrome and ChromeDriver (auto-matched)
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip jq

        # Install Google Chrome (latest stable)
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt-get -f install -y

        # Get installed Chrome version
        CHROME_VERSION=$(google-chrome --version | grep -oP '\d+\.\d+\.\d+\.\d+')
        CHROME_MAJOR=$(echo $CHROME_VERSION | cut -d '.' -f 1)

        # Get matching ChromeDriver download URL
        DRIVER_URL=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/last-known-good-versions-with-downloads.json" \
          | jq -r ".channels.Stable.downloads.chromedriver[] | select(.platform == \"linux64\") | .url" \
          | grep "$CHROME_MAJOR" | head -n 1)

        echo "Downloading ChromeDriver from: $DRIVER_URL"
        wget -O chromedriver.zip "$DRIVER_URL"
        unzip chromedriver.zip
        sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver

    - name: Create Google Service Account Key File
      env:
        GCP_SA_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
      run: |
        echo "${GCP_SA_KEY}" > service_account.json
        chmod 600 service_account.json

    - name: Run the Python script
      run: python scrape_news_to_drive.py

    - name: Upload local output Excel file (for debugging)
      uses: actions/upload-artifact@v4
      with:
        name: debug-scraped-data-${{ github.run_id }}
        path: "*.xlsx"
        retention-days: 1
